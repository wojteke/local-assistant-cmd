2023-06-16 22:19:31.961604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Found cached dataset json (/root/.cache/huggingface/datasets/json/default-5e94923a34c6ffec/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
100% 1/1 [00:00<00:00, 766.78it/s]
Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-5e94923a34c6ffec/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6002895b4b5c7aa8.arrow and /root/.cache/huggingface/datasets/json/default-5e94923a34c6ffec/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-59576cdb38c910d9.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors
100% 100/100 [09:59<00:00,  5.99s/it]
/content/ai-assistant/evaluation.py:66: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  sacrebleu = load_metric('sacrebleu')
Model: gpt2_epoch_2 BLEU Score: 93.4558020278505
100% 100/100 [12:25<00:00,  7.46s/it]
Model: gpt2_lora_epoch_2 BLEU Score: 79.45910027734777
100% 100/100 [19:00<00:00, 11.40s/it]
Model: gpt2-medium_epoch_2 BLEU Score: 92.09971983667695
Downloading (â€¦)lve/main/config.json: 100% 718/718 [00:00<00:00, 3.69MB/s]
Downloading model.safetensors: 100% 1.52G/1.52G [00:08<00:00, 177MB/s]
Downloading (â€¦)neration_config.json: 100% 124/124 [00:00<00:00, 697kB/s]
100% 100/100 [26:09<00:00, 15.70s/it]
Model: gpt2-medium_lora_epoch_2 BLEU Score: 75.60891541606944
100% 100/100 [29:50<00:00, 17.91s/it]
Model: gpt2-large_epoch_2 BLEU Score: 89.45816246349455
Downloading (â€¦)lve/main/config.json: 100% 666/666 [00:00<00:00, 3.80MB/s]
Downloading model.safetensors: 100% 3.25G/3.25G [00:15<00:00, 211MB/s]
Downloading (â€¦)neration_config.json: 100% 124/124 [00:00<00:00, 815kB/s]
100% 100/100 [33:54<00:00, 20.35s/it]
Model: gpt2-large_lora_epoch_2 BLEU Score: 90.1209857265013